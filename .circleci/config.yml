# Python CircleCI 2.1 configuration file
#
# Check https://circleci.com/docs/2.0/language-python/ for more details
#
version: 2.1
orbs:
  slack: circleci/slack@3.4.2
commands:
  update-submodules:
    steps:
      - run:
          # `git submodule update --remote` checks out the submodule repo's
          # HEAD (as opposed to whatever commit is specified in the
          # submodule). We want to ensure we're always testing against
          # the most recent commit in our component-template repo.
          name: Update submodules
          command: |
            git submodule init
            git submodule update --remote

  pre-cache:
    steps:
      - run: &get_make_checksum
          name: Get 'make' checksum
          command: |
            echo 'export SUDO="sudo"' >> $BASH_ENV
            cp -f /usr/bin/make make.bin
            md5sum make.bin > ~/make.md5

      - run: &get_dot_checksum
          name: Get 'dot' checksum
          command: |
            if [ -f /usr/bin/dot ] ; then
              cp -f /usr/bin/dot dot.bin
              md5sum dot.bin > ~/dot.md5
            else
              touch dot.bin
              md5sum dot.bin > ~/dot.md5
              rm -f dot.bin
            fi

      - run: &create_python_cache_key
          # Combine hashes of the Python interpreter, Pipfile, and today's
          # date into a file whose checksum will key the Python virtualenv.
          #
          # This means that our virtualenv cache will expire each day. We do
          # this because we are not using a lockfile to pin dependencies -
          # instead, each time CircleCI rebuilds the virtualenv, it uses the
          # latest compatible version of each dependency (which mirrors what
          # happens when a user installs Streamlit locally). So we expire our
          # virtualenv cache daily to prevent it from getting far out of sync
          # with what a fresh Streamlit installation would look like.
          name: Create Python environment cache key
          command: |
            md5sum $(which python) > ~/python_cache_key.md5
            md5sum lib/Pipfile >> ~/python_cache_key.md5
            md5sum lib/test-requirements.txt >> ~/python_cache_key.md5
            md5sum lib/test-requirements-with-tensorflow.txt >> ~/python_cache_key.md5
            md5sum lib/setup.py >> ~/python_cache_key.md5
            date +%F >> ~/python_cache_key.md5
            # Cache version that can be used to bust the cache before it
            # naturally resets daily. We maintain the convention that the
            # version number is always incremented by 1, but technically it can
            # be reset each day when the previous day's cache expires.
            echo v2 >> ~/python_cache_key.md5

      - run: &create_node_cache_key
          name: Create Node cache key
          command: |
            md5sum frontend/yarn.lock > ~/node_cache_key.md5
            md5sum $(command -v node) >> ~/node_cache_key.md5
            md5sum .nvmrc >> ~/node_cache_key.md5

  restore-from-cache:
    steps:
      - restore_cache: &restore_virtualenv
          name: Restore virtualenv from cache
          keys:
            - v13-python-venv-{{ checksum "~/python_cache_key.md5" }}

      - restore_cache: &restore_nvm
          name: Restore nvm and node_modules from cache
          keys:
            - v13-nvm_node_modules-{{ checksum "~/node_cache_key.md5" }}

      - restore_cache: &restore_make
          name: Restore make from cache
          keys:
            - v13_make.bin-{{ checksum "~/make.md5" }}

      - restore_cache: &restore_dot
          name: Restore dot from cache
          keys:
            - v13_dot.bin-{{ checksum "~/dot.md5" }}

  pre-make:
    steps:
      - run: &install_make
          name: Install make
          command: |
            if [ -s make.bin ] ; then
              echo "make.bin exists; not installing"
            else
              echo "/usr/bin/make doesn't exist; installing"
              apt update
              apt-get install -y make
              cp -f /usr/bin/make make.bin
            fi
            ${SUDO} cp -f make.bin /usr/bin/make

      - run: &install_dot
          name: Install dot
          command: |
            if [ -s dot.bin ] ; then
              echo "dot.bin exists and is non zero"
            else
              echo "/usr/bin/dot doesn't exist, installing"
              ${SUDO} apt update
              ${SUDO} apt-get install -y graphviz
              cp -f /usr/bin/dot dot.bin
            fi
            ${SUDO} cp -f dot.bin /usr/bin/dot

  make-init:
    steps:
      - run: &install_nodejs
          name: Install NVM, Node.js, and Yarn
          command: |
            if [ ! -d ~/.nvm ] ; then
              export NVM_DIR="$HOME/.nvm"
              # install nodejs via nvm
              curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.35.2/install.sh | bash
              # pushd and popd is a workaround for nvm issue
              # See: https://github.com/nvm-sh/nvm/issues/1985
              pushd /tmp
              source "$HOME/.nvm/nvm.sh"
              popd
              nvm install
              # install yarn
              npm install -g yarn
            fi
            if [ ! -d frontend/node_modules ] ; then
              source "$HOME/.nvm/nvm.sh"
              make react-init
            fi
            echo 'export NVM_DIR="$HOME/.nvm"' >> $BASH_ENV
            echo 'source "$NVM_DIR/nvm.sh"' >> $BASH_ENV

      - run:
          name: Install pyodbc dependencies
          command: |
            ${SUDO} apt-get install -y unixodbc-dev

      - run:
          name: Install graphviz dependencies
          command: |
            ${SUDO} apt update
            ${SUDO} apt-get install -y libgvc6

      - run: &activate_virtualenv
          name: Create virtualenv
          command: |
            echo 'Checking for virtualenv'
            if [ ! -d venv ] ; then
              # The virtualenv was NOT restored from cache. Create a new one.
              python3 -m venv venv
              source venv/bin/activate
              pip install --upgrade pip
              make setup
              make pipenv-install
              deactivate
            else
              # The virtualenv WAS restored from cache. Don't create a new one.
              echo 'Virtualenv already exists, not creating'
            fi

            # Add 'activate venv' to $BASH_ENV. This means that our venv will be active
            # for the remainder of the job ($BASH_ENV is evaluated at each step).
            echo 'source venv/bin/activate' >> $BASH_ENV

      - run: &generate_protobufs
          name: Generate protobufs
          command: |
            # install protobuf v3
            ${SUDO} apt update
            ${SUDO} apt-get install -y gnupg
            echo "deb http://ppa.launchpad.net/maarten-fonville/protobuf/ubuntu trusty main" | ${SUDO} tee /etc/apt/sources.list.d/protobuf.list
            ${SUDO} apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 4DEA8909DC6A13A3
            ${SUDO} apt update
            ${SUDO} apt-get install -y protobuf-compiler

            # Generate protobufs
            make protobuf

  configure-build-env:
    steps:
      - update-submodules
      - pre-cache
      - restore-from-cache
      - pre-make

      - save_cache:
          name: Save make to cache
          key: v13_make.bin-{{ checksum "~/make.md5" }}
          paths:
            - make.bin

      - save_cache:
          name: Save dot to cache
          key: v13_dot.bin-{{ checksum "~/dot.md5" }}
          paths:
            - dot.bin

      - make-init

  build-package:
    steps:
      - run:
          name: Make package
          no_output_timeout: 2h
          command: |
            ${SUDO} apt-get install rsync
            make package

  build-package-fast:
    steps:
      - run:
          name: Make package as fast as possible
          no_output_timeout: 2h
          command: |
            ${SUDO} apt-get install rsync
            BUILD_AS_FAST_AS_POSSIBLE=1 make package

workflows:
  circleci:
    jobs:
      - python-min-version: # Oldest supported Python minor version.
          filters:
            tags:
              only: /^(([0-9]+\.){3}dev[0-9]+)/ # 0.56.1.dev20201129
      - python-max-version: # Latest supported Python minor version.
          filters:
            tags:
              only: /^(([0-9]+\.){3}dev[0-9]+)/
      - python-prod-deps-smoke-test: # Make sure Streamlit runs without dev dependencies
          filters:
            tags:
              only: /^(([0-9]+\.){3}dev[0-9]+)/
      - cypress: # Non flaky Cypress tests
          filters:
            tags:
              only: /^(([0-9]+\.){3}dev[0-9]+)/
      - pr-preview: # Make a preview branch for each PR
          filters:
            tags:
              only: /^(([0-9]+\.){3}dev[0-9]+)|(^([0-9]+\.){2}([0-9]+))/
      - cli-regression-test:
          filters:
            tags:
              only: /^(([0-9]+\.){3}dev[0-9]+)/
            branches:
              ignore: /^release\/([0-9]+\.){2}([0-9]+)/
      - nightly-release:
          requires:
            - python-min-version
            - python-max-version
            - cypress
            - python-prod-deps-smoke-test
          filters:
            tags:
              only: /^(([0-9]+\.){3}dev[0-9]+)/
            branches:
              ignore: /.*/
      - build-deploy-rc:
          requires:
            - python-min-version
            - python-max-version
            - cypress
            - python-prod-deps-smoke-test
          filters:
            branches:
              only: /^release\/([0-9]+\.){2}([0-9]+)/
      - build-deploy-release:
          filters:
            tags:
              only: /^([0-9]+\.){2}([0-9]+)/
            branches:
              ignore: /.*/

      # Uncomment to get a button that runs flaky tests on CircleCI:
      # - cypress-flaky-approval:
      #     type: approval
      #     requires:
      #       - python-max-version
      # - cypress: # Flaky Cypress tests
      #     name: cypress-flaky
      #     flaky: true
      #     requires:
      #       - cypress-flaky-approval

  create-nightly-tag:
    triggers:
      - schedule:
          # Run job at 10.30pm PST or 11.30pm PDT
          cron: "30 6 * * *"
          filters:
            branches:
              only:
                - develop
    jobs:
      - create-tag

jobs:
  build-deploy-rc:
    resource_class: large
    docker:
      - image: circleci/python:3.10.1
    working_directory: ~/repo
    steps:
      - checkout:
          name: Checkout Streamlit code

      - configure-build-env

      - run:
          name: Set desired version from branch name
          command: echo 'export DESIRED_VERSION=$(echo $CIRCLE_BRANCH | tr -d "release/")' >> $BASH_ENV

      - run:
          name: Set final versions for pre-release and update version
          command: |
            # Start at the latest existing RC for this version if one exists,
            # so the following update will increment to the right RC version
            export LATEST_MATCHING_RC=$(curl https://pypi.org/pypi/streamlit/json | jq ".releases | keys | map(select(contains(\"rc\"))) | map(select(contains(\"$DESIRED_VERSION\"))) | sort | .[-1]" | tr --delete '"')
            if [ $LATEST_MATCHING_RC != "null" ]; then python scripts/update_version.py $LATEST_MATCHING_RC; fi

            export STREAMLIT_RELEASE_SEMVER=$(python scripts/get_prerelease_version.py $DESIRED_VERSION)
            echo 'export STREAMLIT_RELEASE_SEMVER=$(python scripts/get_prerelease_version.py $DESIRED_VERSION)' >> $BASH_ENV
            echo 'export STREAMLIT_RELEASE_VERSION=$(echo $STREAMLIT_RELEASE_SEMVER | sed s/\-rc\./rc/)' >> $BASH_ENV
            python scripts/update_version.py $STREAMLIT_RELEASE_SEMVER

      - build-package

      - run:
          name: Run CLI regression tests
          command: make cli-regression-tests

      - store_artifacts:
          path: ./lib/dist

      # Password added to circleci environment
      # https://ui.circleci.com/settings/project/github/streamlit/streamlit/environment-variables
      - run:
          name: init .pypirc
          command: |
            cd lib
            echo -e "[pypi]" >> ~/.pypirc
            echo -e "username = $PYPI_USERNAME" >> ~/.pypirc
            echo -e "password = $PYPI_PASSWORD" >> ~/.pypirc

      - run:
          name: Upload to pypi
          command: |
            make distribute

      - slack/status:
          success_message: ":rocket: Release of RC version ${STREAMLIT_RELEASE_SEMVER} was successful!"
          failure_message: ":blobonfire: Release of RC version ${STREAMLIT_RELEASE_SEMVER} failed"

  build-deploy-release:
    resource_class: large
    docker:
      - image: circleci/python:3.10.1
    working_directory: ~/repo
    steps:
      - checkout:
          name: Checkout Streamlit code

      - run:
          name: Install GitHub CLI tool and related dependencies
          command: |
            sudo apt-get install jq
            /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
            eval "$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)"
            brew install gh

      - run:
          name: Configure GitHub CLI Settings
          command: echo 'export GH_REPO=$CIRCLE_PROJECT_USERNAME/$CIRCLE_PROJECT_REPONAME' >> $BASH_ENV

      - run:
          name: Look up the related GitHub PR number and branch name
          command: |
            eval "$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)"
            echo "export GH_PR_BRANCH=$(gh api repos/${GH_REPO}/pulls | jq '[.[] | select(.head.label | contains("release/"))] | .[0] | .head.ref')" >> $BASH_ENV

      - run:
          name: Ensure that version tag matches branch version
          command: |
            if [ "$(echo $GH_PR_BRANCH | tr -d 'release/')" != "$CIRCLE_TAG" ]
            then
              echo "ERROR: Version number from tag does not match the version number from the branch name."
              exit 1
            fi

      - run:
          name: Checkout head of branch
          command: |
            git pull origin ${GH_PR_BRANCH} --ff-only

      - configure-build-env

      - run:
          name: Set release version from tag name
          command: echo 'export STREAMLIT_RELEASE_VERSION=$(echo $CIRCLE_TAG)' >> $BASH_ENV

      - run:
          name: Update version
          command: python scripts/update_version.py $STREAMLIT_RELEASE_VERSION

      - build-package

      - run:
          name: Run CLI regression tests
          command: make cli-regression-tests

      - store_artifacts:
          path: ./lib/dist

      # Password added to circleci environment
      # https://ui.circleci.com/settings/project/github/streamlit/streamlit/environment-variables
      - run:
          name: init .pypirc
          command: |
            cd lib
            echo -e "[pypi]" >> ~/.pypirc
            echo -e "username = $PYPI_USERNAME" >> ~/.pypirc
            echo -e "password = $PYPI_PASSWORD" >> ~/.pypirc

      - run:
          name: Upload to pypi
          command: |
            make distribute

      - run:
          name: Commit version updates
          command: |
            git config user.email "core+streamlitbot-github@streamlit.io"
            git config user.name "Streamlit Bot"

            git switch -c $GH_PR_BRANCH

            git commit -am "Up version to $STREAMLIT_RELEASE_VERSION [skip ci]" && git push origin $GH_PR_BRANCH || echo "No changes to commit"

      - run:
          name: Create GitHub Release
          command: |
            eval "$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)"
            gh release create $CIRCLE_TAG -n "" -t $CIRCLE_TAG

      - slack/status:
          success_message: ":rocket: Release of version ${STREAMLIT_RELEASE_VERSION} was successful!"
          failure_message: ":blobonfire: Release of version ${STREAMLIT_RELEASE_VERSION} failed"

  python-max-version: &job-template
    docker:
      - image: circleci/python:3.10.1

    resource_class: large

    working_directory: ~/repo

    steps:
      - checkout:
          name: Checkout Streamlit code
      - update-submodules
      - pre-cache
      - restore-from-cache
      - pre-make

      - save_cache:
          name: Save make to cache
          key: v13_make.bin-{{ checksum "~/make.md5" }}
          paths:
            - make.bin

      - save_cache:
          name: Save dot to cache
          key: v13_dot.bin-{{ checksum "~/dot.md5" }}
          paths:
            - dot.bin

      - make-init

      - run: &make_develop
          name: Run make develop
          command: |
            make develop

      - run:
          name: Run linters
          command: |
            # Run eslint as a standalone command to generate the test report.
            PRE_COMMIT_NO_CONCURRENCY=true DISABLE=eslint pipenv run pre-commit run --show-diff-on-failure --color=always --all-files
            make jslint

      - store_test_results:
          path: frontend/test-reports
          when: always

      - run:
          name: Run type checkers # tsc is run by pre-commit, thus in this step we only run mypy
          command: |
            scripts/mypy --report

      - store_test_results:
          path: lib/test-reports
          when: always

      - run:
          name: Run python tests
          command: |
            make pycoverage

      - store_test_results:
          path: lib/test-reports
          when: always

      - run:
          name: Run integration tests
          command: |
            make integration-tests

      - run:
          name: CLI smoke tests
          command: |
            make cli-smoke-tests

      - run:
          name: Run frontend tests
          command: |
            if [ "${CIRCLE_JOB}" != "python-max-version" ] ; then
              echo "Frontend tests are only run in python-max-version job"
            else
              make jstest
            fi

      - save_cache:
          name: Save virtualenv to cache
          key: v13-python-venv-{{ checksum "~/python_cache_key.md5" }}
          paths:
            - venv

      - save_cache:
          name: Save nvm, pre-commit cache and node_modules to cache
          key: v13-nvm_node_modules-{{ checksum "~/node_cache_key.md5" }}-{{ checksum "~/repo/.pre-commit-config.yaml" }}
          paths:
            - ~/.nvm
            - ~/.cache
            - frontend/node_modules

      - when:
          condition: <<pipeline.git.tag>>
          steps:
            - slack/status:
                fail_only: true
                failure_message: ":blobonfire: Nightly job failed on unit tests"

  # The following inherits from python-max-version. In a few cases, steps are skipped
  # based on the name of the current job (see, e.g., "Run frontend tests").
  python-min-version:
    <<: *job-template
    docker:
      - image: circleci/python:3.7.12

  python-prod-deps-smoke-test:
    docker:
      - image: circleci/python:3.10.1

    working_directory: ~/repo

    steps:
      - checkout:
          name: Checkout Streamlit code
      - update-submodules
      - pre-cache

      - restore_cache:
          <<: *restore_nvm

      - restore_cache:
          <<: *restore_make

      - restore_cache:
          <<: *restore_dot

      - pre-make

      - run:
          <<: *install_nodejs

      - run:
          name: Create virtualenv
          command: |
            python3 -m venv venv
            source venv/bin/activate
            pip install --upgrade pip
            pip install pipenv mypy mypy-protobuf 'protobuf<4'
            deactivate

            # Add 'activate venv' to $BASH_ENV. This means that our venv will be active
            # for the remainder of the job ($BASH_ENV is evaluated at each step).
            echo 'source venv/bin/activate' >> $BASH_ENV

      - run:
          <<: *generate_protobufs

      - run:
          name: Run make init develop
          command: |
            make init develop

      - run:
          name: CLI smoke tests
          command: |
            make cli-smoke-tests

  create-tag:
    docker:
      - image: circleci/python:3.10.1

    working_directory: ~/repo

    steps:
      - checkout:
          name: Checkout Streamlit code

      - update-submodules

      - pre-cache
      - restore-from-cache
      - pre-make
      - make-init

      - run:
          <<: *make_develop

      - run:
          name: Create tag
          # TODO move git commands into script
          command: |
            git config user.email "core+streamlitbot-github@streamlit.io"
            git config user.name "Streamlit Bot"

            TAG="$(./scripts/pypi_nightly_create_tag.py)"

            ./scripts/update_version.py $TAG
            ./scripts/update_name.py streamlit-nightly

            git add lib/setup.py
            git add frontend/package.json

            git add lib/streamlit/__init__.py
            git add lib/streamlit/version.py

            git commit -m "Update version and project name in files"

            git tag -a $TAG -m "Streamlit nightly $TAG"
            git push origin $TAG

      - slack/status:
          fail_only: true
          failure_message: ":blobonfire: Nightly job failed to create a tag"

  nightly-release:
    docker:
      - image: circleci/python:3.10.1

    resource_class: large

    working_directory: ~/repo

    steps:
      - checkout:
          name: Checkout Streamlit code

      - update-submodules

      - pre-cache
      - restore-from-cache
      - pre-make
      - make-init

      - run:
          name: verify git tag vs. version
          command: |
            cd lib
            python setup.py verify

      # Password added to circleci environment
      # https://ui.circleci.com/settings/project/github/streamlit/streamlit/environment-variables
      - run:
          name: init .pypirc
          command: |
            cd lib
            echo -e "[pypi]" >> ~/.pypirc
            echo -e "username = $PYPI_USERNAME" >> ~/.pypirc
            echo -e "password = $PYPI_PASSWORD" >> ~/.pypirc

      - build-package

      - run:
          name: upload to pypi
          command: |
            make distribute

      - slack/status:
          fail_only: true
          failure_message: ":blobonfire: Nightly job failed to release"

  pr-preview:
    docker:
      - image: circleci/python:3.10.1

    resource_class: large

    working_directory: ~/repo

    steps:
      - add_ssh_keys:
          name: Add the read/write Github deploy key
          fingerprints:
            - "98:67:1f:37:d6:4d:21:f3:46:5d:e2:c9:a3:58:52:39"

      - checkout:
          name: Checkout Streamlit code

      - update-submodules
      - pre-cache
      - restore-from-cache
      - pre-make
      - make-init

      - run:
          name: Create wheel file
          no_output_timeout: 2h
          command: |
            ${SUDO} apt-get install rsync
            BUILD_AS_FAST_AS_POSSIBLE=1 make package

      - run:
          name: Set PREVIEW_BRANCH envvar
          command: |
            echo "export PREVIEW_BRANCH=$(
              if [[ -n "${CIRCLE_PR_NUMBER}" ]]
              then
                echo "pr-${CIRCLE_PR_NUMBER}"
              elif [[ -n "${CIRCLE_BRANCH}" ]]
              then
                echo "${CIRCLE_BRANCH}-preview"
              elif [[ -n "${CIRCLE_TAG}" ]]
              then
                echo "tag-${CIRCLE_TAG}"
              else
                echo "main-preview"
              fi
            )" >> $BASH_ENV

      - run:
          name: Upload wheel to S3
          command: |
            ${SUDO} apt-get install -y awscli
            aws configure set aws_access_key_id ${CORE_PREVIEWS_S3_KEY_ID}
            aws configure set aws_secret_access_key ${CORE_PREVIEWS_S3_SECRET_KEY}

            cd lib/dist
            export WHEELFILE="$(ls -t *.whl | head -n 1)"

            if [ ${CIRCLE_BRANCH} = "release/demo" ]
            then
              aws s3 cp ${WHEELFILE} s3://core-previews/${PREVIEW_BRANCH}/streamlit-11.11.11-py2.py3-none-any.whl --acl public-read
              echo -e "Here is the link to download the wheel file: https://core-previews.s3-us-west-2.amazonaws.com/${PREVIEW_BRANCH}/streamlit-11.11.11-py2.py3-none-any.whl"
            else
              aws s3 cp ${WHEELFILE} s3://core-previews/${PREVIEW_BRANCH}/ --acl public-read
              echo -e "Here is the link to download the wheel file: https://core-previews.s3-us-west-2.amazonaws.com/${PREVIEW_BRANCH}/${WHEELFILE}"
            fi

            cd ../..
            echo -e "https://core-previews.s3-us-west-2.amazonaws.com/${PREVIEW_BRANCH}/${WHEELFILE}" >> S3_URL

      - run:
          name: Setup preview repo
          command: |
            git config --global user.email "core+streamlitbot-github@streamlit.io"
            git config --global user.name "Streamlit Bot"
            git clone git@github.com:streamlit/core-previews.git

            cd core-previews
            git branch -D ${PREVIEW_BRANCH} &>/dev/null || true
            git checkout -b ${PREVIEW_BRANCH}

            cat ../S3_URL >> requirements.txt

            git add .
            git commit -m "Prepare core preview: ${PREVIEW_BRANCH}"
            git push -f origin ${PREVIEW_BRANCH}

      - run:
          name: Ready to deploy!
          command: |
            echo -e "https://share.streamlit.io/deploy?repository=streamlit/core-previews&branch=${PREVIEW_BRANCH}&mainModule=streamlit_app.py"

  cypress:
    docker:
      - image: circleci/python:3.7.11
    parallelism: 20

    resource_class: xlarge

    working_directory: ~/repo

    parameters:
      flaky:
        description: "Run flaky tests"
        default: false
        type: boolean

    steps:
      - checkout:
          name: Checkout Streamlit code

      - update-submodules

      - pre-cache
      - restore-from-cache
      - pre-make
      - make-init

      - run:
          <<: *make_develop

      - run:
          name: Install Cypress dependencies
          command: |
            ${SUDO} apt-get install -y xvfb libgtk2.0-0 libnotify-dev libgconf-2-4 libnss3 libxss1 libasound2 jq curl

      - run:
          name: Init config
          command: |
            mkdir ~/.streamlit
            MAPBOX_TOKEN=$(curl -sS https://data.streamlit.io/tokens.json | jq -r '.["mapbox-localhost"]')
            echo '[mapbox]' >  ~/.streamlit/config.toml
            echo 'token = "'$MAPBOX_TOKEN'"' >> ~/.streamlit/config.toml

      - run:
          name: Init credentials
          command: |
            echo '[general]' >  ~/.streamlit/credentials.toml
            echo 'email = "test@streamlit.io"' >> ~/.streamlit/credentials.toml

      - when:
          condition: << parameters.flaky >>
          steps:
            - run:
                name: Cypress
                # See comment below, in the "unless << parameters.flaky >>".
                command: |
                  cd frontend
                  TEST=$(circleci tests glob ../e2e/specs/*.spec.js | circleci tests split --split-by=timings)
                  ../scripts/run_e2e_tests.py -a -f $TEST

      - unless:
          condition: << parameters.flaky >>
          steps:
            - run:
                name: Cypress
                # Need to run from frontend directory, because
                # cypress-circleci-reporter reports paths relative to there.
                #
                # `circleci tests split` splits our long-running Cypress e2e
                # tests into N different parallel jobs, so that they finish
                # much faster than if we run them in sequence. CircleCI makes
                # sure each container that calls `circleci test split` receives
                # its share of the test files.
                command: |
                  cd frontend
                  TEST=$(circleci tests glob ../e2e/specs/*.spec.js | circleci tests split --split-by=timings)
                  ../scripts/run_e2e_tests.py -a $TEST

      - store_test_results: &store_results
          path: frontend/test_results/cypress
          when: always

      - store_artifacts: &store_videos
          path: frontend/cypress/videos

      - store_artifacts: &store_snapshots
          path: frontend/cypress/snapshots

      - save_cache:
          name: Save virtualenv to cache
          key: v13-python-venv-{{ checksum "~/python_cache_key.md5" }}
          paths:
            - venv

      - save_cache:
          name: Save nvm and node_modules to cache
          key: v13-nvm_node_modules-{{ checksum "~/node_cache_key.md5" }}
          paths:
            - ~/.nvm
            - ~/.cache
            - frontend/node_modules

      - when:
          condition: <<pipeline.git.tag>>
          steps:
            - slack/status:
                fail_only: true
                failure_message: ":blobonfire: Nightly job failed on E2E tests"

  cli-regression-test:
    resource_class: large
    docker:
      - image: circleci/python:3.10.1
    working_directory: ~/repo
    steps:
      - checkout:
          name: Checkout Streamlit code

      - configure-build-env

      - build-package-fast

      - run:
          name: Run CLI regression tests
          command: |
            export SKIP_VERSION_CHECK=true
            make cli-regression-tests

  local-e2e-env-test:
    # To have local Docker, use a machine executor.
    # The Docker executor provides access to a remote docker which does not
    # have support for mounting local directories as a volume
    # This is also in line with how Github Action works.
    machine:
      image: ubuntu-2204:2022.07.1
    working_directory: ~/repo
    steps:
      - checkout:
          name: Checkout Streamlit code

      - run:
          name: Install system dependencies
          command: |
            sudo apt-get update -y
            sudo apt-get install -y libmariadb-dev

      - update-submodules

      - pre-cache
      - restore-from-cache
      - pre-make
      - make-init

      - run:
          name: Build image
          command: |
            make build-test-env

      - run:
          name: Run single tests
          command: |
            ./e2e/run_compose.py ./scripts/run_e2e_tests.py -u ./e2e/specs/st_code.spec.js